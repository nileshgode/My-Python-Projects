{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Classification_NLP",
      "provenance": [],
      "authorship_tag": "ABX9TyPgsqgVKC573NFF6KAWQOZw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "46XXGoDNJE1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_fszw6jJR4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "574ca511-5218-43b4-d6a8-4ebdc331894a"
      },
      "source": [
        "#PRINT VERSION!!\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBu2Pu7JVAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = ('https://media.githubusercontent.com/media/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/master/section_1_notebooks/train_languages.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSlnGwQUJd4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "40cebe93-f133-4483-aff6-d7072b2d0081"
      },
      "source": [
        "train_df = pd.read_csv(filepath)#here we have the dataset we extracted\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jean Beauverie (Fontaines-sur-Saône, 18 febbra...</td>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Il pinguino saltarocce (Eudyptes chrysocome (F...</td>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maison Ikkoku - Cara dolce Kyoko (めぞん一刻 Mezon ...</td>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La mia città è un singolo della cantante itali...</td>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L'Armata Rossa dei Lavoratori e dei Contadini ...</td>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence language\n",
              "0  Jean Beauverie (Fontaines-sur-Saône, 18 febbra...  italian\n",
              "1  Il pinguino saltarocce (Eudyptes chrysocome (F...  italian\n",
              "2  Maison Ikkoku - Cara dolce Kyoko (めぞん一刻 Mezon ...  italian\n",
              "3  La mia città è un singolo della cantante itali...  italian\n",
              "4  L'Armata Rossa dei Lavoratori e dei Contadini ...  italian"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naO9wgr9JlzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c0db526-4924-4a70-c910-7f1165e214b9"
      },
      "source": [
        "len(train_df) #we print the length, not a big one but sufficient"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLvYzCgRJqIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = train_df['language']\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "Y = tf.keras.utils.to_categorical(\n",
        "    Y,\n",
        "    num_classes=4                       #equals to the number of languages\n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS7lx22pJz6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['sentence_lower'] = train_df[\"sentence\"].str.lower()\n",
        "train_df['sentence_no_punctuation'] = train_df['sentence_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['sentence_no_punctuation'] = train_df[\"sentence_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dA1vcMkKP44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "62101115-357c-4e88-cb97-ab07a3ffbb82"
      },
      "source": [
        "print(train_df['sentence_no_punctuation'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       jean beauverie fontainessursaône 18 febbraio 1...\n",
            "1       il pinguino saltarocce eudyptes chrysocome for...\n",
            "2       maison ikkoku  cara dolce kyoko めぞん一刻 mezon ik...\n",
            "3       la mia città è un singolo della cantante itali...\n",
            "4       larmata rossa dei lavoratori e dei contadini i...\n",
            "                              ...                        \n",
            "3628    el premio internacional de novela emilio alarc...\n",
            "3629    la mujer más fea del mundo es una película esp...\n",
            "3630    bacuag también conocido como  bacnag es un mun...\n",
            "3631    violent femmes es una banda de rock alternativ...\n",
            "3632    james guthrie grenock escocia10 de junio de 18...\n",
            "Name: sentence_no_punctuation, Length: 3633, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAHuGz1zJ5-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features=5000                #we set maximum number of words to 5000\n",
        "maxlen=400                       #we set maximum sequence length to 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLsvLowQJ_vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)                 #again tokenizer step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQvlk284KFUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok.fit_on_texts(list(train_df['sentence_no_punctuation'])) #fit to cleaned text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejmvh0JTKg3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a3f80f-9196-4b08-dbf6-c8a334a173bc"
      },
      "source": [
        "print(len(tok.word_index))\n",
        "vocab_size = len(tok.word_index) + 1 \n",
        "#this represents the number of words that we tokenize different from max_features but necessary for\n",
        "#the definition of the dimension of the embedding space"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3j3RrNxKmOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = tok.texts_to_sequences(list(train_df['sentence_no_punctuation']))                   #this is how we create sequences\n",
        "train_df = tf.keras.preprocessing.sequence.pad_sequences(train_df, maxlen=maxlen)              #let's execute pad step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imjD1FxdKsRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split                                           #divide into train and test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEVQqNKqKxFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df, Y, test_size=0.1, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRgA-ZLLK1Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50                                                                              #this is the final dimension of the embedding space."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JP1uWyhK6AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(input_dim=vocab_size,            #embedding input\n",
        "                           output_dim=embedding_dim,         #embedding output\n",
        "                           input_length=maxlen),             #maximum length of an input sequence\n",
        "  tf.keras.layers.Flatten(),                                 #flatten layer\n",
        "\n",
        "  tf.keras.layers.Dense(4, activation=tf.nn.softmax)         #ouput layer a Dense layer with 4 probabilities\n",
        "  #we also define our final activation function which is the softmax function typical for multiclass\n",
        "  #classifiction problems\n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LerfAPoNLGoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',               #we recommend this loss function you\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PEy9J2sLLpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "701e95bd-cdc8-4ac0-a213-afd3dbd00eb2"
      },
      "source": [
        "model.summary()                                              #here we show the architecture"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 50)           2581550   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 80004     \n",
            "=================================================================\n",
            "Total params: 2,661,554\n",
            "Trainable params: 2,661,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKNrgCvQLSiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3dc14b28-00ba-43f3-e9a6-92e41d8aceda"
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train), epochs=10)    #let's fit the model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 3s 32ms/step - loss: 0.8449 - accuracy: 0.7134\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 3s 32ms/step - loss: 0.0819 - accuracy: 0.9972\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0262 - accuracy: 0.9976\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0150 - accuracy: 0.9979\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0106 - accuracy: 0.9976\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0081 - accuracy: 0.9982\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 3s 32ms/step - loss: 0.0057 - accuracy: 0.9985\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 3s 33ms/step - loss: 0.0052 - accuracy: 0.9985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd072886a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTxuY97HLu7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29e819a2-0bcf-43d5-a679-68f4c08b336a"
      },
      "source": [
        "model.evaluate(np.array(X_test), np.array(y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.011290659196674824, 0.9972527623176575]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0E_QwSLxuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix #we import this package from sklearn and output it\n",
        "predictions = model.predict(X_test) #here we make predictions\n",
        "cm = confusion_matrix(predictions.argmax(axis=1), y_test.argmax(axis=1))#we generate the confusion matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aezpVwcAL3iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8d22e18a-6905-4792-91a3-dff4277160ca"
      },
      "source": [
        "cm #well this is really perfect!"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 65,   0,   0,   0],\n",
              "       [  0, 101,   0,   0],\n",
              "       [  1,   0,  96,   0],\n",
              "       [  0,   0,   0, 101]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7qCuq5wL_J5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "75752804-b207-4a3d-a63a-31333e8ade7f"
      },
      "source": [
        "#these are the codes for each language in order to evaluate properly\n",
        "print('english', encoder.transform(['english']))\n",
        "print('french', encoder.transform(['french']))\n",
        "print('italian', encoder.transform(['italian']))\n",
        "print('spanish', encoder.transform(['spanish']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english [0]\n",
            "french [1]\n",
            "italian [2]\n",
            "spanish [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qFbtPjQMI-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_text = [\"tensorflow is a great tool you can find a lot of tutorials from packt\"]\n",
        "#new_text = [\"tensorflow est un excellent outil vous pouvez trouver beaucoup de tutoriels de packt\"]\n",
        "#new_text = [\"tensorflow è un ottimo strumento puoi trovare molti tutorial di packt\"]\n",
        "new_text = [\"tensorflow es una gran herramienta puedes encontrar muchos tutoriales de packt\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FBd2hijMKWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = tok.texts_to_sequences(new_text) #this is how we create sequences\n",
        "test_text = tf.keras.preprocessing.sequence.pad_sequences(test_text, maxlen=maxlen) #let's execute pad step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHijX43lMOAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fa9aec7-b2e7-4bd1-f8c6-3c9e8b5fe001"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "predictions = model.predict(test_text)\n",
        "print(predictions.argmax())\n",
        "print(predictions) #spanish you can get confused with italian which makes sense since they are more similar languages"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[[0.01087021 0.02892438 0.05692278 0.90328264]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_HXlh9HMRvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install wikipedia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EECCxVW2M4hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wikipedia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkKZCfsDMfEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a0e30989-af30-4408-9e43-a6e9f1db0561"
      },
      "source": [
        "#language codes\n",
        "#english: en\n",
        "#italian: it\n",
        "#french: fr\n",
        "#spanish: es\n",
        "new_wiki_text = []\n",
        "wikipedia.set_lang('es')\n",
        "for i in range(0, 5):\n",
        "    print(i)\n",
        "    random = wikipedia.random(1)\n",
        "       \n",
        "    try:\n",
        "        new_wiki_text.append([wikipedia.page(random).summary])\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        random = wikipedia.random(1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6zyV9qsM-CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2534916e-8186-4fdd-89a4-57c33a2c230f"
      },
      "source": [
        "new_wiki_text = pd.DataFrame(new_wiki_text)\n",
        "new_wiki_text.columns = ['sentence']\n",
        "new_wiki_text"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Penthesilea (título original en alemán; en esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>El rascón de Wallace (Habroptila wallacii)[2]​...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El aeródromo Sitry (en inglés: Sitry Skiway) f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tocar el cielo es una película que se estrenó ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Atrévete a soñar es la primera banda sonora de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence\n",
              "0  Penthesilea (título original en alemán; en esp...\n",
              "1  El rascón de Wallace (Habroptila wallacii)[2]​...\n",
              "2  El aeródromo Sitry (en inglés: Sitry Skiway) f...\n",
              "3  Tocar el cielo es una película que se estrenó ...\n",
              "4  Atrévete a soñar es la primera banda sonora de..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xsBxYZRNF_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_wiki_text['sentence_lower'] = new_wiki_text[\"sentence\"].str.lower()\n",
        "new_wiki_text['sentence_no_punctuation'] = new_wiki_text['sentence_lower'].str.replace('[^\\w\\s]','')\n",
        "new_wiki_text['sentence_no_punctuation'] = new_wiki_text[\"sentence_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD1oqL6oNKsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "test_wiki_text = tok.texts_to_sequences(list(new_wiki_text['sentence_no_punctuation'] )) #this is how we create sequences\n",
        "test_wiki_text = tf.keras.preprocessing.sequence.pad_sequences(test_wiki_text, maxlen=maxlen) #let's execute pad step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdmgovr0NO_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a5d77f8f-fd31-4e52-db85-02215052f9bb"
      },
      "source": [
        "predictions = model.predict(test_wiki_text)\n",
        "print(predictions)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00000005 0.00000296 0.0000001  0.9999969 ]\n",
            " [0.00000008 0.00000344 0.00000005 0.9999964 ]\n",
            " [0.00000033 0.00000094 0.00000127 0.9999975 ]\n",
            " [0.00000001 0.00000013 0.00000004 0.99999976]\n",
            " [0.00000731 0.00016868 0.00001349 0.9998105 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qxdVbrkNWLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8a391736-0df5-4550-f877-05d15263c52d"
      },
      "source": [
        "print('english', encoder.transform(['english']))\n",
        "print('french', encoder.transform(['french']))\n",
        "print('italian', encoder.transform(['italian']))\n",
        "print('spanish', encoder.transform(['spanish']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english [0]\n",
            "french [1]\n",
            "italian [2]\n",
            "spanish [3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}